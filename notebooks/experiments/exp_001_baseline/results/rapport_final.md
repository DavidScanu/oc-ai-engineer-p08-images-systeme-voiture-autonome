
# Rapport d'Ã‰valuation - ModÃ¨le de Segmentation SÃ©mantique

## ğŸ·ï¸ Identification de l'ExpÃ©rience
- **Nom de l'expÃ©rience**: exp_001_baseline
- **Description**: Baseline MobileNetV2-UNet avec frozen encoder
- **Date d'Ã©valuation**: 2025-05-23 11:40:11

## âš™ï¸ Configuration du ModÃ¨le
- **Architecture**: MobileNetV2-UNet
- **Backbone**: MobileNetV2 (ImageNet prÃ©-entraÃ®nÃ©)
- **Encoder trainable**: False
- **Classes de segmentation**: 8 groupes
- **Groupes de classes**: flat, human, vehicle, construction, object, nature, sky, void

## ğŸ“‹ ParamÃ¨tres d'EntraÃ®nement
- **Taille d'image**: (224, 224)
- **Batch size**: 8
- **Ã‰poques d'entraÃ®nement**: N/A
- **Taux d'apprentissage**: 0.0001
- **Division validation**: 0.2
- **Augmentation de donnÃ©es**: True

## ğŸ“Š Performances Finales sur Dataset de Test
- **Perte finale**: 0.4123
- **PrÃ©cision finale**: 0.8795
- **MeanIoU finale**: 0.6325

## ğŸ¯ Dataset et Ã‰valuation
- **Dataset**: Cityscapes (segmentation urbaine)
- **Split utilisÃ© pour test**: Dataset 'val' original (Ã©vite data leakage)
- **Nombre d'images de test**: ~500 images
- **MÃ©thode d'Ã©valuation**: IoU par classe, prÃ©cision globale, matrice de confusion

## ğŸ“ˆ Mapping des Classes
Les 30+ classes originales de Cityscapes ont Ã©tÃ© regroupÃ©es en 8 catÃ©gories pertinentes 
pour la navigation autonome:

1. **Flat** (0): Routes, trottoirs, parkings
2. **Human** (1): Personnes, cyclistes  
3. **Vehicle** (2): Voitures, camions, bus, motos, vÃ©los
4. **Construction** (3): BÃ¢timents, murs, clÃ´tures, ponts
5. **Object** (4): Poteaux, panneaux, feux de circulation
6. **Nature** (5): VÃ©gÃ©tation, terrain
7. **Sky** (6): Ciel
8. **Void** (7): Pixels non Ã©tiquetÃ©s ou hors rÃ©gion d'intÃ©rÃªt

## ğŸš— Applications et DÃ©ploiement
- **Cas d'usage**: SystÃ¨me de vision pour vÃ©hicules autonomes
- **Format de modÃ¨le**: Keras (.keras) - compatible TensorFlow Lite
- **Optimisations**: MobileNetV2 conÃ§u pour l'efficacitÃ© mobile
- **IntÃ©gration**: API FastAPI + Frontend Next.js (en dÃ©veloppement)

## ğŸ“‚ Artefacts GÃ©nÃ©rÃ©s
- **ModÃ¨le entraÃ®nÃ©**: `experiments/exp_001_baseline/models/final_model.keras`
- **Configuration**: `experiments/exp_001_baseline/results/experiment_config.json`
- **Historique d'entraÃ®nement**: `experiments/exp_001_baseline/results/training_history.json`
- **MÃ©triques dÃ©taillÃ©es**: `experiments/exp_001_baseline/results/`
- **Visualisations**: Matrice de confusion, exemples de prÃ©dictions

## ğŸ”„ Suivi et ReproductibilitÃ©
- **Structure d'expÃ©riences**: Organisation modulaire par dossiers
- **IntÃ©gration MLflow**: Suivi des mÃ©triques et artefacts
- **Graine alÃ©atoire**: 42 (reproductibilitÃ© garantie)
- **Environnement**: TensorFlow 2.18.0, Keras 3.8.0

## ğŸ“ Notes Techniques
- Le modÃ¨le utilise SparseCategoricalCrossentropy comme fonction de perte
- L'encoder MobileNetV2 peut Ãªtre gelÃ© ou entraÃ®nable selon la configuration
- La segmentation est rÃ©alisÃ©e Ã  224x224 puis peut Ãªtre redimensionnÃ©e
- L'augmentation de donnÃ©es inclut flip horizontal et variation de luminositÃ©

## ğŸ¯ Recommandations
1. **Pour amÃ©liorer les performances**: ConsidÃ©rer l'entraÃ®nement avec encoder dÃ©gelÃ©
2. **Pour le dÃ©ploiement**: Conversion en TensorFlow Lite pour l'optimisation mobile
3. **Pour l'Ã©valuation**: Utiliser des mÃ©triques IoU par classe pour l'analyse dÃ©taillÃ©e
4. **Pour la production**: ImplÃ©menter une validation croisÃ©e sur plusieurs datasets urbains

---
*Rapport gÃ©nÃ©rÃ© automatiquement le 2025-05-23 Ã  11:40:11*
