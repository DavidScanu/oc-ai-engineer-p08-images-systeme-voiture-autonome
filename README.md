# Projet 8 : Traitement d'images pour le systÃ¨me embarquÃ© d'une voiture autonome

![Keras](https://img.shields.io/badge/Keras-Framework-D00000?logo=keras&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-async%20API-009688?logo=fastapi&logoColor=white)
![Next.js](https://img.shields.io/badge/Next.js-frontend-000000?logo=next.js&logoColor=white)
![Railway](https://img.shields.io/badge/Railway-deployment-0B0D0E?logo=railway&logoColor=white)
![Vercel](https://img.shields.io/badge/Vercel-frontend-000000?logo=vercel&logoColor=white)

> ğŸ“ OpenClassrooms â€¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | ğŸ‘‹ *Ã‰tudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)

## ğŸŒ Contexte

Ce projet s'inscrit dans le dÃ©veloppement d'un **systÃ¨me embarquÃ© de vision par ordinateur** pour vÃ©hicules autonomes chez **Future Vision Transport**. L'entreprise conÃ§oit des systÃ¨mes permettant aux vÃ©hicules autonomes de percevoir leur environnement grÃ¢ce Ã  l'analyse d'images en temps rÃ©el.

## âš¡ Mission

En tant qu'ingÃ©nieur IA dans l'Ã©quipe R&D, notre mission est de **dÃ©velopper le module de segmentation d'images** (composant 3) qui s'intÃ¨gre entre le module de traitement d'images (2) et le systÃ¨me de dÃ©cision (4). Ce module doit Ãªtre capable d'**identifier et de segmenter prÃ©cisÃ©ment 8 catÃ©gories principales d'objets** dans des images de camÃ©ras embarquÃ©es utilisant le dataset Cityscapes.

### ğŸ—ï¸ Architecture du SystÃ¨me EmbarquÃ©
```
[1] Acquisition â†’ [2] Traitement â†’ [3] SEGMENTATION â†’ [4] DÃ©cision
   d'images      d'images         (Notre rÃ´le)      finale
```

## ğŸ¯ Objectifs Techniques

- **ModÃ¨le IA** : DÃ©velopper un modÃ¨le de segmentation sÃ©mantique MobileNetV2-UNet avec Keras/TensorFlow
- **API Production** : Concevoir et dÃ©ployer une API REST avec FastAPI sur Railway
- **Interface Demo** : CrÃ©er une application web de visualisation avec Next.js sur Vercel
- **Pipeline MLOps** : Mettre en place un suivi d'expÃ©riences avec MLflow
- **Documentation** : Produire un rapport technique et une prÃ©sentation professionnelle

## ğŸ—“ï¸ MÃ©thodologie

### 1. **Exploration et PrÃ©paration des DonnÃ©es**
- Analyse du dataset **Cityscapes** (5000 images annotÃ©es, 50 villes europÃ©ennes)
- **Regroupement de 30+ classes** en 8 catÃ©gories pertinentes pour la navigation
- **Pipeline de prÃ©processing** : Redimensionnement 2048Ã—1024 â†’ 224Ã—224
- **Augmentation de donnÃ©es** : Flip horizontal, variations de luminositÃ©

### 2. **DÃ©veloppement du ModÃ¨le**
- **Architecture hybride** : MobileNetV2 (encodeur) + U-Net (dÃ©codeur)
- **Transfer learning** : Encodeur prÃ©-entraÃ®nÃ© sur ImageNet (gelÃ©)
- **EntraÃ®nement** : 18 Ã©poques, callbacks optimisÃ©s (EarlyStopping, ReduceLROnPlateau)
- **Suivi MLflow** : Versioning et traÃ§abilitÃ© des expÃ©riences

### 3. **DÃ©ploiement et Interface**
- **API FastAPI** : Endpoints de prÃ©diction avec gÃ©nÃ©ration d'artefacts visuels
- **Frontend Next.js** : Interface intuitive d'upload et visualisation
- **Architecture cloud** : Railway (backend) + Vercel (frontend)

### 4. **Ã‰valuation et Optimisation**
- **MÃ©triques** : Mean IoU, PrÃ©cision pixel-wise, Analyse par classe
- **Validation rigoureuse** : Train/Val/Test split avec prÃ©vention du data leakage

## ğŸ—ï¸ Architecture du Projet

```
oc-ai-engineer-p08-images-systeme-voiture-autonome/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ backend/                 # API FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py             # Point d'entrÃ©e FastAPI
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration et variables
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ predictor.py    # Logique de prÃ©diction
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ segmentation.py # Endpoints API
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â””â”€â”€ prediction.py   # ModÃ¨les Pydantic
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ image_processing.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ frontend/               # Application Next.js
â”‚       â”œâ”€â”€ components/         # Composants React
â”‚       â”œâ”€â”€ pages/             # Pages de l'application
â”‚       â”œâ”€â”€ public/            # Ressources statiques
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ next.config.js
â”œâ”€â”€ notebooks/                  # DÃ©veloppement du modÃ¨le
â”‚   â””â”€â”€ p08_david_scanu_notebook_MobileNetV2_UNet.ipynb.ipynb
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ p08_david_scanu_rapport_technique.pdf
â”‚   â””â”€â”€ p08_david_scanu_presentation.pdf
â”œâ”€â”€ app/backend/railway.json   # Config dÃ©ploiement Railway
â””â”€â”€ README.md
```

## ğŸ”§ Technologies UtilisÃ©es

### **Deep Learning & Data Science**
- **TensorFlow 2.18** / **Keras 3.x** : DÃ©veloppement du modÃ¨le MobileNetV2-UNet
- **MLflow** : Gestion des expÃ©riences et versioning des modÃ¨les
- **NumPy**, **Pandas** : Manipulation de donnÃ©es
- **Pillow**, **OpenCV** : Traitement d'images

### **Backend & API**
- **FastAPI** : Framework web asynchrone pour l'API REST
- **Uvicorn** / **Gunicorn** : Serveurs ASGI pour la production
- **Pydantic** : Validation et sÃ©rialisation des donnÃ©es

### **Frontend & Interface**
- **Next.js 15.3** : Framework React pour l'interface utilisateur
- **Bootstrap 5.3** : Framework CSS responsive
- **Fetch API** : Communication avec l'API backend

### **DÃ©ploiement & Infrastructure**
- **Railway** : DÃ©ploiement cloud de l'API FastAPI
- **Vercel** : DÃ©ploiement de l'application Next.js
- **AWS S3** : Stockage des artefacts MLflow

## ğŸ“Š Performances du ModÃ¨le

### ğŸ¯ **RÃ©sultats Globaux**
- **Mean IoU** : **63.25%**
- **PrÃ©cision pixel-wise** : **87.95%**
- **Convergence** : 18 Ã©poques (~2h d'entraÃ®nement)
- **ParamÃ¨tres** : 5.4M (3.6M entraÃ®nables)

### ğŸ† **Performance par CatÃ©gorie (IoU)**
| CatÃ©gorie | IoU | Importance Navigation |
|-----------|-----|----------------------|
| ğŸ›£ï¸ **flat** | **90.8%** | ğŸ”´ Critique |
| â˜ï¸ **sky** | **83.4%** | ğŸŸ¢ Contextuel |
| ğŸŒ³ **nature** | **79.8%** | ğŸŸ¢ Contextuel |
| ğŸš— **vehicle** | **74.7%** | ğŸ”´ Critique |
| ğŸ¢ **construction** | **74.5%** | ğŸŸ¡ Important |
| âš« **void** | **64.3%** | âš« Technique |
| ğŸ‘¤ **human** | **32.0%** | ğŸ”´ Critique |
| ğŸš¦ **object** | **6.5%** | ğŸŸ¡ Important |

### âœ… **Points Forts**
- **Excellence** sur les surfaces planes et structures dominantes
- **Performance temps rÃ©el** compatible avec les contraintes embarquÃ©es
- **Architecture optimisÃ©e** pour les ressources limitÃ©es

### âš ï¸ **Axes d'AmÃ©lioration**
- **DÃ©tection des objets fins** (panneaux, poteaux) Ã  amÃ©liorer
- **Segmentation des humains** variable selon le contexte
- **EntraÃ®nement progressif** avec dÃ©gelage de l'encodeur envisageable

## ğŸš€ Installation et DÃ©ploiement

### **PrÃ©requis**
- Python 3.10+
- Node.js 16+
- Compte MLflow avec accÃ¨s S3

### **Backend API FastAPI**

Pour lancer l'API FastAPI, suivez ces Ã©tapes :

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/DavidScanu/oc-ai-engineer-p08-images-systeme-voiture-autonome.git
cd oc-ai-engineer-p08-images-systeme-voiture-autonome/app/backend

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement
export MLFLOW_TRACKING_URI="your-mlflow-uri"
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
export RUN_ID="your-experiment-run-id"
export FRONTEND_URL=http://localhost:3000
export PORT=8000

# Lancer l'API
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### **Frontend Next.js**

Pour lancer l'interface utilisateur, suivez ces Ã©tapes :

```bash
cd ../frontend

# Installer les dÃ©pendances
npm install

# Configurer l'URL de l'API
export NEXT_PUBLIC_API_URL="http://localhost:8000"

# Lancer en dÃ©veloppement
npm run dev
```

## ğŸ“‹ Livrables

### **DÃ©veloppement & Code**
- **Code complet** : [GitHub Repository](https://github.com/DavidScanu/oc-ai-engineer-p08-images-systeme-voiture-autonome)
- **Notebook de dÃ©veloppement** : [Google Colab](https://colab.research.google.com/drive/1jZ2tdEyJ2xaERUCwyQ5juwPJrEyIAtBN?usp=sharing)

### **Applications DÃ©ployÃ©es**
- **API FastAPI de production** : DÃ©ployÃ©e sur Railway (URL non-protÃ©gÃ©e disponible sur demande)
- **Interface Next.js** : DÃ©ployÃ©e sur Vercel (URL non-protÃ©gÃ©e disponible sur demande)

### **Documentation**
- **Rapport technique** : [Google Docs](https://docs.google.com/document/d/1ACjrsOGwafw-D72CgmbF6DkU7bktG7OnPxmPL99inCU/edit?usp=sharing)
- **Article technique complet** : [dev.to](https://dev.to/davidscanu/segmentation-dimages-pour-pour-le-systeme-embarque-dune-voiture-autonome-2f5e/)
- **Support de prÃ©sentation** : [Google Slides](https://docs.google.com/presentation/d/10sbXJKSd5XwDln6k0y3O-i1Ev7iUPg58iz36Pi6NGkk/edit?usp=sharing)


## ğŸ”® Perspectives d'Ã‰volution

### **AmÃ©liorations ModÃ¨le**
- **EntraÃ®nement progressif** : DÃ©gelage de l'encodeur en phase 2
- **Augmentation avancÃ©e** : Simulation mÃ©tÃ©orologique (pluie, brouillard)
- **Architecture multi-Ã©chelles** : AmÃ©lioration de la robustesse

### **Optimisations SystÃ¨me**
- **Authentification API** : SÃ©curisation des endpoints
- **Cache intelligent** : Optimisation des temps de rÃ©ponse
- **Monitoring avancÃ©** : MÃ©triques de performance en production

### **IntÃ©gration Industrielle**
- **Fusion multi-sensorielle** : Combinaison avec radar/lidar
- **Optimisation embarquÃ©e** : Quantization et pruning
- **Pipeline temps rÃ©el** : Traitement vidÃ©o en continu

---

## ğŸ‘‹ Ã€ Propos

**Projet dÃ©veloppÃ© par [David Scanu](https://www.linkedin.com/in/davidscanu14/)** dans le cadre du parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) d'OpenClassrooms.